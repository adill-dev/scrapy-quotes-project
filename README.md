# ğŸ“š Scrapy Quotes Crawler

This project is a simple **web scraper** built using [Scrapy](https://scrapy.org/) that extracts quotes and author information from [quotes.toscrape.com](https://quotes.toscrape.com/).

## ğŸš€ Features

- Crawls quotes from the main and paginated pages
- Follows author profile links
- Scrapes the following author details:
  - Full name
  - Date of birth
  - Short biography
- Supports exporting scraped data to JSON, CSV, or XML

## ğŸ“ Project Structure

scrapy_quotes/
â”œâ”€â”€ scrapy_quotes/
â”‚ â”œâ”€â”€ init.py
â”‚ â”œâ”€â”€ items.py
â”‚ â”œâ”€â”€ middlewares.py
â”‚ â”œâ”€â”€ pipelines.py
â”‚ â”œâ”€â”€ settings.py
â”‚ â””â”€â”€ spiders/
â”‚ â”œâ”€â”€ init.py
â”‚ â””â”€â”€ author_spider.py
â”œâ”€â”€ scrapy.cfg


## ğŸ•· Spider Details

### `author_spider.py`

- **Spider Name**: `author`
- **Start URL**: `https://quotes.toscrape.com/`
- **Extracts** author links and paginated quote pages using CSS selectors
- For each author, it scrapes:
  - `name` â€“ full name of the author
  - `dob` â€“ date of birth
  - `bio` â€“ short biography

### Example Extracted Data

```json
{
  "name": "Albert Einstein",
  "dob": "March 14, 1879",
  "bio": "Lorem ipsum author biography..."
}

ğŸ§ª How to Run the Spider
Install Scrapy (if not already installed):

pip install scrapy


Navigate to your project directory:

cd scrapy_quotes


Run the spider and export data:

scrapy crawl author -o authors.json

Supported formats: .json, .csv, .xml, etc.

ğŸ§± Requirements
Python 3.7 or higher

Scrapy (tested on Scrapy 2.13.3)

Install dependencies:

pip install -r requirements.txt
If requirements.txt is not present, just install Scrapy directly using pip install scrapy.