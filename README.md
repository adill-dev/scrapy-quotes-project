
# ğŸ“š Scrapy Quotes Crawler

This project is a simple **web scraper** built using [Scrapy](https://scrapy.org/) that extracts quotes and author information from [quotes.toscrape.com](https://quotes.toscrape.com/).

## ğŸš€ Features

- Crawls quotes from the main and paginated pages
- Follows author profile links
- Scrapes the following author details:
  - Full name
  - Date of birth
  - Short biography
- Supports exporting scraped data to JSON, CSV, or XML

## ğŸ“ Project Structure

```
scrapy_quotes/
â”œâ”€â”€ scrapy_quotes/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ items.py
â”‚   â”œâ”€â”€ middlewares.py
â”‚   â”œâ”€â”€ pipelines.py
â”‚   â”œâ”€â”€ settings.py
â”‚   â””â”€â”€ spiders/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â””â”€â”€ author_spider.py
â”œâ”€â”€ scrapy.cfg
```

## ğŸ•· Spider Details

### `author_spider.py`

- **Spider Name**: `author`
- **Start URL**: `https://quotes.toscrape.com/`
- **Extracts** author links and paginated quote pages using CSS selectors
- For each author, it scrapes:
  - `name` â€“ full name of the author
  - `dob` â€“ date of birth
  - `bio` â€“ short biography

### ğŸ§ª Example Extracted Data

```json
{
  "name": "Albert Einstein",
  "dob": "March 14, 1879",
  "bio": "Lorem ipsum author biography..."
}
```

## ğŸ§ª How to Run the Spider

### Install Scrapy (if not already installed):

```bash
pip install scrapy
```

### Navigate to your project directory:

```bash
cd scrapy_quotes
```

### Run the spider and export data:

```bash
scrapy crawl author -o authors.json
```

Supported formats: `.json`, `.csv`, `.xml`, etc.

## ğŸ§± Requirements

- Python 3.7 or higher
- Scrapy (tested on Scrapy 2.13.3)

### Install dependencies:

```bash
pip install -r requirements.txt
```

If `requirements.txt` is not present, just install Scrapy directly using:

```bash
pip install scrapy
```
